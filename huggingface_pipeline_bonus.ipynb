{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a4a282c",
   "metadata": {},
   "source": [
    "# 🎁 Hugging Face Pipeline Bonus Tasks\n",
    "This notebook builds on the core pipeline demo by introducing more advanced and diverse LLM tasks — ready-to-run with Hugging Face pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db633100",
   "metadata": {},
   "source": [
    "## 📝 1. Summarization\n",
    "Used to compress long documents or paragraphs into key points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9764a544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082d71c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "ACSPRI is a consortium of leading Australian universities, offering intensive short courses in research methods and data analysis. Their LLM course introduces foundational tools and workflows for using large language models in social science applications.\n",
    "\"\"\"\n",
    "summarized = summarizer(text)\n",
    "print(summarized[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6260d4",
   "metadata": {},
   "source": [
    "## 🌍 2. Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1581e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = pipeline(\"translation_en_to_de\")\n",
    "print(translator(\"LLMs are changing the landscape of qualitative research.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5246e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator_fr = pipeline(\"translation_en_to_fr\")\n",
    "translator_fr(\"This report highlights several policy recommendations for climate change mitigation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c875218",
   "metadata": {},
   "source": [
    "✅ Works with many common pairs: `en_to_de`, `en_to_fr`, `en_to_es`, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3cc1ec",
   "metadata": {},
   "source": [
    "## 🧾 3. Text Classification\n",
    "Similar to sentiment but more flexible — used for news topic detection, user intent, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86768741",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"text-classification\")\n",
    "classifier(\"This article discusses the economic impact of AI technology.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3208ef",
   "metadata": {},
   "source": [
    "## 🕵️ 4. Named Entity Recognition (NER)\n",
    "Detects and categorizes names, locations, organizations, dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55006d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"Dr. Maria Prokofieva works at Victoria University in Melbourne.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2a45ef",
   "metadata": {},
   "source": [
    "## 🔍 5. Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966728c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = pipeline(\"question-answering\")\n",
    "context = \"Maria is a researcher and academic who teaches LLM methods at ACSPRI.\"\n",
    "qa(question=\"Who teaches LLM methods?\", context=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27d31c5",
   "metadata": {},
   "source": [
    "## 🧠 Recap\n",
    "These advanced pipelines are still 1–2 lines of code each — but open doors to high-level research workflows:\n",
    "- Extract structured metadata\n",
    "- Translate multilingual surveys\n",
    "- Auto-label long-form text\n",
    "- Query internal knowledge docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b420c556",
   "metadata": {},
   "source": [
    "### 🔗 What’s Next?\n",
    "You’ll now begin combining logic and outputs from multiple sources. We’ll explore **input pipelines** and **how LLMs interpret your prompts and data** in the next module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6354f9b7",
   "metadata": {},
   "source": [
    "📘 Continue to: [`llm_input_pipeline.md`](../llm_input_pipeline)\n",
    "\n",
    "> From tasks to pipelines → from pipelines to products."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
