{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0ecc8a1",
   "metadata": {},
   "source": [
    "# üì¶ LLM Response Explainer\n",
    "This notebook walks through how to **read, interpret, and programmatically use the output** returned by large language models (LLMs) using popular libraries like Hugging Face Transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ef099b",
   "metadata": {},
   "source": [
    "## üßæ Structure of LLM Responses\n",
    "LLMs typically return a list of one or more dictionaries. Each dictionary contains the model‚Äôs prediction and relevant metadata.\n",
    "\n",
    "The **keys** inside these dictionaries tell you:\n",
    "- What the model *thinks* the label/class is (e.g., `label` or `answer`)\n",
    "- How *confident* it is (`score`)\n",
    "- Optionally, where the answer is located (e.g., `start`, `end`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a24d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "response = classifier(\"This is fantastic!\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c6ceeb",
   "metadata": {},
   "source": [
    "### üßæ Sample Output Format:\n",
    "```python\n",
    "[{'label': 'POSITIVE', 'score': 0.9987}]\n",
    "```\n",
    "\n",
    "üìå This output is wrapped in a list, so you must access the `[0]` element before using dictionary keys like `'label'` or `'score'`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd60795",
   "metadata": {},
   "source": [
    "## üîç Step 1: Access Specific Fields\n",
    "Use Python‚Äôs dictionary syntax to access values inside the response dictionary. This is important when you want to extract results for tables, JSON, CSV, or downstream workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13135393",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = response[0]['label']\n",
    "confidence = round(response[0]['score'], 3)\n",
    "print(f\"Label: {label}, Confidence: {confidence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3892fd",
   "metadata": {},
   "source": [
    "### ‚úÖ Why This Matters\n",
    "If you don‚Äôt extract values properly, you‚Äôll either get an error or use incorrect data. For example, calling `response[\"label\"]` without the `[0]` will throw a `TypeError`, since `response` is a list."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410d783f",
   "metadata": {},
   "source": [
    "## üîÅ Step 2: Working with Batches (Multiple Inputs)\n",
    "You can send a list of text inputs to the model and receive a list of outputs. The order of results matches the order of inputs ‚Äî this is guaranteed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9e5ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"I love this\", \"This is bad\", \"Maybe\"]\n",
    "responses = classifier(texts)\n",
    "for text, resp in zip(texts, responses):\n",
    "    print(f\"{text} ‚Üí {resp['label']} ({resp['score']:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab91c2a2",
   "metadata": {},
   "source": [
    "### üìò Tips:\n",
    "- Always use `zip()` to pair input texts with responses\n",
    "- Loop over batches for scalable logging, export, or analytics\n",
    "- Use `round(resp['score'], 2)` to simplify outputs for display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d83f61a",
   "metadata": {},
   "source": [
    "## üß± Step 3: Wrap the Logic into a Reusable Function\n",
    "Functions let you reuse logic and clean your notebook. You‚Äôll need this for:\n",
    "- Logging model predictions\n",
    "- Saving results to a file\n",
    "- Combining with data pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6fcb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_response(text):\n",
    "    result = classifier(text)[0]\n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"label\": result['label'],\n",
    "        \"confidence\": round(result['score'], 2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc01e5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_response(\"Great work!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534d13b1",
   "metadata": {},
   "source": [
    "### üìå How This Helps\n",
    "- You can later wrap `explain_response()` inside a `.apply()` on a DataFrame\n",
    "- You can extend it to save into a database or visualize in a UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9237a1be",
   "metadata": {},
   "source": [
    "## üß¨ Step 4: Special Output Formats ‚Äì QA Example\n",
    "Some models return additional fields ‚Äî for example, **question answering** includes the start and end position of the answer inside the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69525d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = pipeline(\"question-answering\")\n",
    "qa_output = qa(\n",
    "    question=\"Who teaches this course?\",\n",
    "    context=\"Maria teaches this ACSPRI course on LLMs.\"\n",
    ")\n",
    "print(qa_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dae960",
   "metadata": {},
   "source": [
    "### Sample Output:\n",
    "```python\n",
    "{'score': 0.98, 'start': 0, 'end': 5, 'answer': 'Maria'}\n",
    "```\n",
    "This means:\n",
    "- The model found the answer `'Maria'`\n",
    "- It‚Äôs 98% confident\n",
    "- The answer starts at character 0 and ends at character 5 in the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7df50db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can extract individual fields like this:\n",
    "qa_output['answer'], round(qa_output['score'], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c2a0d6",
   "metadata": {},
   "source": [
    "üìå Start/end indices are especially useful if you're building UI tools that highlight the answer inside a paragraph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637116ef",
   "metadata": {},
   "source": [
    "## üß† Summary: How to Use LLM Output Properly\n",
    "| Task                | Output Format                  | What You Extract         |\n",
    "|---------------------|-------------------------------|---------------------------|\n",
    "| Sentiment Analysis  | List of dicts                 | `label`, `score`          |\n",
    "| Question Answering  | Single dict                   | `answer`, `score`, `span` |\n",
    "| Translation         | List of dicts with `translation_text` |                       |\n",
    "| Named Entity Recognition | List of entities        | `entity`, `word`, `score` |\n",
    "\n",
    "‚úÖ Always inspect structure with `print()` or `type()` before using the result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6e96f1",
   "metadata": {},
   "source": [
    "From here, you‚Äôll start combining outputs into classification logic or decision rules."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
