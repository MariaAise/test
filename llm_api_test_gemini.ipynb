{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a2e335e",
   "metadata": {},
   "source": [
    "# üß™ Gemini API ‚Äì Basic Inference Test in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e69f979",
   "metadata": {},
   "source": [
    "\n",
    "This notebook demonstrates how to use the **Google Generative AI SDK** to interact with **Gemini 1.5 Pro** and **Gemini Flash** models.\n",
    "\n",
    "You'll learn how to:\n",
    "- Authenticate using your Gemini API key\n",
    "- Send basic and structured prompts\n",
    "- Handle file input and multimodal payloads\n",
    "- Generate structured output (e.g., JSON or tables)\n",
    "- Understand and handle common response formats\n",
    "\n",
    "Gemini models are accessed via [`google.generativeai`](https://pypi.org/project/google-generativeai/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6160e6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d067e528",
   "metadata": {},
   "source": [
    "## üîê Setup API Key & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61bba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "# Set API key (Use secret management for production)\n",
    "genai.configure(api_key=\"YOUR_GEMINI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459f5371",
   "metadata": {},
   "source": [
    "## üß† Basic Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38bdb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
    "response = model.generate_content(\"What are 3 key benefits of AI in education?\")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3c3b7c",
   "metadata": {},
   "source": [
    "## üß± System Prompt + Few-shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e803f9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = '''You are a research assistant. Provide responses in bullet points.\n",
    "\n",
    "Q: How can AI help in medical research?\n",
    "A:\n",
    "- Accelerates drug discovery\n",
    "- Analyzes complex datasets\n",
    "- Identifies patterns in genomic data\n",
    "'''\n",
    "\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e83c70a",
   "metadata": {},
   "source": [
    "## üì¶ Generate Structured JSON Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e560ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = model.generate_content(\n",
    "    \"List 3 popular AI models in JSON with keys: name, developer, release_year\"\n",
    ")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de03d19",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Multimodal Prompt (Text + Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f980cf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "image_path = \"example_image.jpg\"\n",
    "with open(image_path, \"rb\") as img:\n",
    "    image_data = img.read()\n",
    "\n",
    "response = model.generate_content(\n",
    "    [\"Describe this image briefly:\", image_data]\n",
    ")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c0ef3c",
   "metadata": {},
   "source": [
    "## ‚ùå Common Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e6e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    bad_model = genai.GenerativeModel(\"unknown-model\")\n",
    "    bad_model.generate_content(\"Test\")\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463a006e",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Summary\n",
    "\n",
    "In this notebook, you:\n",
    "- Installed and configured Gemini SDK\n",
    "- Ran basic and structured prompts\n",
    "- Generated JSON and multimodal responses\n",
    "- Handled model errors safely\n",
    "\n",
    "Explore `api_inference_quickstart.md` for multi-provider setup.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
