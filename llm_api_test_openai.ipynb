{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa285227",
   "metadata": {},
   "source": [
    "# üß† OpenAI API Test ‚Äì Basic ChatCompletion\n",
    "\n",
    "This notebook demonstrates how to send a prompt to OpenAI's GPT models using the `openai` Python package. You'll test message formatting, temperature, max token usage, and more.\n",
    "\n",
    "‚úÖ Designed for ACSPRI and Maria Aise GitBook workflows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4e7c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "An API key is a secure identifier that authenticates your access to a cloud service‚Äîin this case, OpenAI.\n",
    "Think of it as a personalized access card: OpenAI uses it to verify who you are, enforce usage limits, and track billing.\n",
    "\n",
    "In Python, we typically avoid typing API keys directly into code (called hardcoding). Instead, we use os.environ to read them from a secure environment variable. This prevents accidental sharing.\n",
    "\n",
    "import os\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")  # Secure way\n",
    "\n",
    "If you're using Colab, you can set the environment variable in a cell using:\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = 'your-key-here'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397ff07a",
   "metadata": {},
   "source": [
    "## üß† What is `ChatCompletion`?\n",
    "`ChatCompletion` is a specialized API endpoint in the OpenAI Python SDK designed for **multi-turn conversations**.\n",
    "It uses the same structure as ChatGPT ‚Äî every prompt is represented as a list of message objects with clear speaker roles:\n",
    "\n",
    "- `system`: sets context and behavior for the assistant (tone, goals, etc.)\n",
    "- `user`: represents user instructions\n",
    "- `assistant`: (optional) past responses to continue a thread\n",
    "\n",
    "You can simulate real dialogue, enforce a certain persona, or frame the assistant with highly controlled prompting.\n",
    "\n",
    "üìò This is more powerful than the old `Completion` API because it supports **rich interaction flow** and history-aware behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ede5a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "This function sends your prompt to OpenAI‚Äôs server and returns a generated response.\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a concise and helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"List 3 ways LLMs can assist social science research.\"}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=200\n",
    ")\n",
    "\n",
    "### ‚öôÔ∏è Parameters Explained:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### üí° How to Make the Prompt Work Better:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97456b3b",
   "metadata": {},
   "source": [
    "## üì¶ What does the response contain?\n",
    "This full response is a dictionary (Python's version of a named list).\n",
    "You can explore different keys such as:\n",
    "- `id` ‚Üí unique ID for the call\n",
    "- `model` ‚Üí which model was used\n",
    "- `usage` ‚Üí token breakdown (prompt vs completion)\n",
    "- `choices[0]['message']['content']` ‚Üí this is your result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582015d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f7e713",
   "metadata": {},
   "source": [
    "## üìò Where can I find more options?\n",
    "- Visit the official OpenAI Python docs: https://platform.openai.com/docs/guides/chat\n",
    "- Try the [OpenAI Playground](https://platform.openai.com/playground) to test prompt settings visually\n",
    "- Look at the function signature in Python: `help(openai.ChatCompletion.create)`## ‚úÖ Tips\n",
    "- Use `temperature=0.3` for factual tasks, `0.7+` for creative ones.\n",
    "- Adjust `max_tokens` based on desired output length.\n",
    "- Use `gpt-4` if available for better reasoning.\n",
    "- Log payloads for debugging: `print(json.dumps(...))`.\n",
    "\n",
    "---\n",
    "**Related GitBook Modules:** `api_key_setup.md`, `openai_api_basic_call.md`, `api_inference_quickstart.md`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199930cf",
   "metadata": {},
   "source": [
    "# üß™ Use Case 1: Summarising Interview Transcripts\n",
    "For qualitative researchers, LLMs can extract meaning from open-ended responses or interview logs.\n",
    "\n",
    "üëâ Let's simulate asking GPT to summarise an interview:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade42b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a research assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Summarise the following paragraph in 2 bullet points: \\\n",
    "‚ÄòThe participant described their experience of burnout during COVID lockdown. They expressed feelings of isolation, professional stagnation, and emotional exhaustion. However, they also mentioned building new coping mechanisms such as mindfulness and starting a support group.‚Äô\"}\n",
    "  ]\n",
    ")\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56e203b",
   "metadata": {},
   "source": [
    "# üß™ Use Case 2: Policy Brief from a News Article\n",
    "LLMs can quickly extract key messages for time-poor public servants.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda97506",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a government policy analyst assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Create a 3-sentence briefing note from this: \\\n",
    "‚ÄòRecent data from the Australian Bureau of Statistics shows a 12% increase in mental health service use among rural populations in 2024. Experts cite rising cost-of-living and GP shortages as major drivers.‚Äô\"}\n",
    "  ]\n",
    ")\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc70960d",
   "metadata": {},
   "source": [
    "# üß™ Use Case 3: Code Explainer for New Users\n",
    "Help interpret Python code ‚Äî useful for upskilling teams unfamiliar with programming.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecdabe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a Python tutor for beginners.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Explain what this code does in plain English: \\\n",
    "for name in [\\\"Alice\\\", \\\"Bob\\\"]:\\n    print(\\\"Hello\\\", name)\"}\n",
    "  ]\n",
    ")\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
