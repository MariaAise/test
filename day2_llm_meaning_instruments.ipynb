{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27afb730",
   "metadata": {},
   "source": [
    "# üìò Day 2 ‚Äì LLMs as Semantic Instruments\n",
    "\n",
    "This notebook explores how LLMs encode and measure meaning using embeddings, and compares interpretive (Gemini) vs quantitative (Hugging Face) approaches.\n",
    "\n",
    "> Core goal: Understand how sentence meaning is computed, visualized, and contrasted.\n",
    "\n",
    "**Sections:**\n",
    "1. Gemini Meaning Probes\n",
    "2. Hugging Face Embeddings\n",
    "3. Meaning Matrix Heatmap\n",
    "4. Semantic Drift\n",
    "5. Annotator Simulation (optional)\n",
    "6. Recap and What‚Äôs Next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bcc66d",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Gemini Meaning Probes\n",
    "\n",
    "Use Google Gemini (via API) to interpret sentence meaning.\n",
    "\n",
    "‚û°Ô∏è Requires a free [Gemini API key](https://makersuite.google.com/app/apikey)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69223c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"YOUR_API_KEY_HERE\")  # Replace with your key\n",
    "model = genai.GenerativeModel(\"gemini-pro\")\n",
    "\n",
    "prompt = \"Compare the meaning of: 'The minister supported the bill.' and 'The minister opposed the bill.'\"\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b1fb1a",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Hugging Face Sentence Embeddings\n",
    "\n",
    "We now compute vector representations using `sentence-transformers`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a712eb",
   "metadata": {},
   "source": [
    "\n",
    "> üîç **Why `all-MiniLM-L6-v2`?**\n",
    ">\n",
    "> - It is **small and fast**, ideal for live demos or classroom settings.\n",
    "> - Trained specifically for **semantic similarity tasks**, making it highly effective for comparing sentence meanings.\n",
    "> - Outputs **384-dimensional vectors**, balancing speed with representational depth.\n",
    "> - Part of the `sentence-transformers` library, maintained by Hugging Face and SBERT.net.\n",
    "> - Pretrained on **general and question-answer datasets**, making it robust for diverse domains.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c45ed88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "sentences = [\n",
    "    \"The minister supported the bill.\",\n",
    "    \"The minister opposed the bill.\",\n",
    "    \"The bill was popular among voters.\",\n",
    "    \"Many citizens disagreed with the proposal.\"\n",
    "]\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "print(\"Embedding shape:\", embeddings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd8c938",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Meaning Matrix Heatmap\n",
    "\n",
    "We compute cosine similarity between sentence embeddings and plot a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03e8ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sim_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(sim_matrix, xticklabels=sentences, yticklabels=sentences, annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Cosine Similarity Between Sentences\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eec513",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Semantic Drift Demo\n",
    "\n",
    "Example showing how small changes in wording can change meaning vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36743854",
   "metadata": {},
   "outputs": [],
   "source": [
    "drift_sentences = [\n",
    "    \"The protest was peaceful.\",\n",
    "    \"The riot turned violent.\",\n",
    "    \"The demonstration gathered thousands.\",\n",
    "    \"The violent clash disrupted the city.\"\n",
    "]\n",
    "\n",
    "drift_embeddings = model.encode(drift_sentences)\n",
    "drift_sim = cosine_similarity(drift_embeddings)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(drift_sim, xticklabels=drift_sentences, yticklabels=drift_sentences, annot=True, cmap=\"YlGnBu\")\n",
    "plt.title(\"Semantic Drift ‚Äì Framing Differences\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a41b8d9",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Annotator Disagreement Simulation *(Optional)*\n",
    "\n",
    "Simulate two annotators assigning sentiment to the same set of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c175e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coder_A = [\n",
    "    \"The project was successful.\",\n",
    "    \"The project had issues.\",\n",
    "    \"The plan worked well.\",\n",
    "    \"The initiative was flawed.\"\n",
    "]\n",
    "\n",
    "coder_B = [\n",
    "    \"The plan was a success.\",\n",
    "    \"There were serious flaws.\",\n",
    "    \"The outcome was positive.\",\n",
    "    \"The result was problematic.\"\n",
    "]\n",
    "\n",
    "emb_A = model.encode(coder_A)\n",
    "emb_B = model.encode(coder_B)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "combined = np.vstack([emb_A, emb_B])\n",
    "labels = ['A']*4 + ['B']*4\n",
    "pca = PCA(n_components=2)\n",
    "reduced = pca.fit_transform(combined)\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "for i, label in enumerate(labels):\n",
    "    plt.scatter(reduced[i, 0], reduced[i, 1], label=f\"{label} {i%4 + 1}\")\n",
    "plt.title(\"Annotator Meaning Space\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa3495d",
   "metadata": {},
   "source": [
    "## üîÅ Recap & What‚Äôs Next\n",
    "\n",
    "- Gemini shows qualitative interpretation\n",
    "- HF gives numerical vectors\n",
    "- Cosine and PCA reveal deep semantic structure\n",
    "\n",
    "‚û°Ô∏è In Session 2, we‚Äôll use these vectors for classification, clustering, and retrieval.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1969ea80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
