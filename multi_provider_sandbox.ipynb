{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df17473",
   "metadata": {},
   "source": [
    "# ü§ñ Multi-Provider LLM Sandbox ‚Äì Gemini vs OpenAI vs Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513038cd",
   "metadata": {},
   "source": [
    "\n",
    "This notebook demonstrates how to **run the same prompt across three major LLM providers**:\n",
    "\n",
    "- **Gemini (Google AI Studio)**\n",
    "- **OpenAI (ChatCompletion)**\n",
    "- **Hugging Face (Inference API)**\n",
    "\n",
    "You'll see how different models:\n",
    "- Interpret the same prompt\n",
    "- Return different levels of detail, formatting, or factuality\n",
    "- Can be tuned to converge on a consistent style or tone\n",
    "\n",
    "---\n",
    "\n",
    "## üß† Why Do LLM Outputs Differ?\n",
    "\n",
    "Each model is trained on:\n",
    "- Different datasets\n",
    "- Different architectures (transformer variants, attention heads)\n",
    "- Different alignment objectives (instruction-following, safety, speed)\n",
    "\n",
    "They also vary by:\n",
    "- Context length\n",
    "- Temperature settings\n",
    "- Output formatting capabilities\n",
    "\n",
    "---\n",
    "\n",
    "## üß™ Evaluation Strategy\n",
    "\n",
    "When comparing LLM outputs:\n",
    "- ‚úÖ Look for *semantic similarity*: do they express the same core idea?\n",
    "- üéØ Check *tone and format*: do they suit your intended use case?\n",
    "- üß† Consider *reasoning depth*: factual density, hallucinations, and logic\n",
    "\n",
    "You can use:\n",
    "- Human review (best for policy/qual)\n",
    "- Cosine similarity (for embeddings)\n",
    "- Prompt-level scoring (via another LLM)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bc15e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install -q openai google-generativeai requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80244964",
   "metadata": {},
   "source": [
    "## üîê Set API Keys and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb8485",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import openai\n",
    "import google.generativeai as genai\n",
    "import requests\n",
    "\n",
    "# Set your keys (for demo only ‚Äì use env vars in real use)\n",
    "openai.api_key = \"sk-...\"\n",
    "genai.configure(api_key=\"your-gemini-api-key\")\n",
    "hf_token = \"hf_...\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15f860c",
   "metadata": {},
   "source": [
    "## üì• Shared Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336566f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = \"Summarize the risks and benefits of AI in healthcare in 3 bullet points.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28cfd20",
   "metadata": {},
   "source": [
    "## üîÆ Gemini Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf58e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gemini_model = genai.GenerativeModel(\"gemini-1.5-pro\")\n",
    "gemini_response = gemini_model.generate_content(prompt)\n",
    "print(\"Gemini:\n",
    "\", gemini_response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0732d77a",
   "metadata": {},
   "source": [
    "## üß† OpenAI Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddf7606",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a concise assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")\n",
    "print(\"OpenAI:\n",
    "\", response['choices'][0]['message']['content'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cb710a",
   "metadata": {},
   "source": [
    "## ü§ñ Hugging Face Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b916262",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "headers = {\"Authorization\": f\"Bearer {hf_token}\"}\n",
    "url = \"https://api-inference.huggingface.co/models/google/flan-t5-large\"\n",
    "\n",
    "response = requests.post(url, headers=headers, json={\"inputs\": prompt})\n",
    "print(\"Hugging Face:\n",
    "\", response.json())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913ff9d7",
   "metadata": {},
   "source": [
    "## üéõÔ∏è Tips to Improve Output Across Providers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7ca0c2",
   "metadata": {},
   "source": [
    "\n",
    "| Provider    | Best Practices                                                              |\n",
    "|-------------|------------------------------------------------------------------------------|\n",
    "| Gemini      | Use clear structure, few-shot if needed, supports image+text                |\n",
    "| OpenAI      | Use system message to control tone, try temperature 0.3‚Äì0.7                 |\n",
    "| Hugging Face| Choose task-specific model (`flan-t5`, `bart`, `bloom`), tune parameters    |\n",
    "\n",
    "Try:\n",
    "- Adding `\"Respond in JSON format\"` or `\"Use short bullet points\"`\n",
    "- Breaking large instructions into steps\n",
    "- Using examples (`few-shot prompting`) to guide structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922f883b",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ‚úÖ Summary\n",
    "\n",
    "You‚Äôve now:\n",
    "- Run side-by-side completions across Gemini, OpenAI, and HF\n",
    "- Compared format, fluency, and precision\n",
    "- Learned how to tune for more consistent or tailored output\n",
    "\n",
    "üìò For more: see `api_inference_quickstart.md` or `compare_gemini_vs_hf.md`\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
