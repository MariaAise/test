{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7d1d7d4",
   "metadata": {},
   "source": [
    "# ü§ñ Hugging Face Pipeline Demo (Detailed)\n",
    "Welcome to your **first real interaction with a pre-trained LLM** using Hugging Face's `transformers` library.\n",
    "\n",
    "In this notebook, you will:\n",
    "- Install the required library\n",
    "- Load a pre-trained model\n",
    "- Run real text inputs (single + batch)\n",
    "- Wrap this logic in a reusable function\n",
    "- Explore bonus tasks like summarization and translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0328c9",
   "metadata": {},
   "source": [
    "## üì¶ Step 1: Install Transformers Library\n",
    "We‚Äôll use Hugging Face‚Äôs `transformers`, which includes model access, tokenizers, and simplified pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b75ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd84e6f",
   "metadata": {},
   "source": [
    "üìò The `transformers` library lets you run:\n",
    "- Sentiment analysis\n",
    "- Text classification\n",
    "- Summarization\n",
    "- Named entity recognition (NER)\n",
    "- Question answering\n",
    "- Translation\n",
    "\n",
    "You‚Äôll access all this with just a few lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f60a185",
   "metadata": {},
   "source": [
    "üì∏ *Screenshot placeholder: Hugging Face model card: distilbert-base-uncased-finetuned-sst-2-english*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58396388",
   "metadata": {},
   "source": [
    "## üß† Step 2: Load Sentiment Analysis Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be664cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b001e1e",
   "metadata": {},
   "source": [
    "‚úÖ This automatically:\n",
    "- Downloads the model\n",
    "- Loads its tokenizer\n",
    "- Wraps them in a single function call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed70feda",
   "metadata": {},
   "source": [
    "## üí¨ Step 3: Run a Single Text Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6926c466",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I love using language models for research.\"\n",
    "result = classifier(text)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c430d750",
   "metadata": {},
   "source": [
    "### üßæ Output format:\n",
    "You‚Äôll get a list of dictionaries:\n",
    "```python\n",
    "[{'label': 'POSITIVE', 'score': 0.9997}]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750195ca",
   "metadata": {},
   "source": [
    "### üß™ Try it with variations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dbde53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classifier(\"This is terrible.\"))\n",
    "print(classifier(\"Mediocre at best.\"))\n",
    "print(classifier(\"Absolutely phenomenal experience!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57840f03",
   "metadata": {},
   "source": [
    "üì∏ *Screenshot placeholder: notebook showing results from 3 texts (POS/NEG labels)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4654e5de",
   "metadata": {},
   "source": [
    "## üîÅ Step 4: Batch Processing\n",
    "Most LLM workflows involve *many* text inputs (from documents, surveys, transcripts, etc.). You can pass multiple texts to the pipeline at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a04d955",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"I love this product!\",\n",
    "    \"It doesn‚Äôt work well.\",\n",
    "    \"Not sure how I feel.\"\n",
    "]\n",
    "\n",
    "results = classifier(texts)\n",
    "\n",
    "for text, output in zip(texts, results):\n",
    "    print(f\"{text} ‚Üí {output['label']} ({output['score']:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1af452",
   "metadata": {},
   "source": [
    "üìå This is **essential** when classifying large datasets ‚Äî like survey answers or interview segments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663e0c3f",
   "metadata": {},
   "source": [
    "## üß© Step 5: Reusable Function (LLM Workflow Block)\n",
    "Let‚Äôs wrap everything above into a Python function you can reuse across sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a8a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_texts(text_list):\n",
    "    results = classifier(text_list)\n",
    "    return [(t, r['label'], round(r['score'], 2)) for t, r in zip(text_list, results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cb2cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the function:\n",
    "classify_texts([\"Amazing quality.\", \"So disappointing.\", \"Neutral vibe.\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19b58d8",
   "metadata": {},
   "source": [
    "üì∏ *Screenshot placeholder: formatted output as list of (text, label, score)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a21c5a6",
   "metadata": {},
   "source": [
    "## üìö Step 6: Bonus Tasks ‚Äî Other Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f3c2bd",
   "metadata": {},
   "source": [
    "### üìù Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e9cbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarizer = pipeline(\"summarization\")\n",
    "summary = summarizer(\"\"\"\n",
    "The COVID-19 pandemic has led to unprecedented global disruption. Governments around the world responded with lockdowns, travel bans, and emergency healthcare measures. Vaccination efforts ramped up quickly, but social and economic impacts continue to unfold.\n",
    "\"\"\")\n",
    "print(summary[0]['summary_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c6a455",
   "metadata": {},
   "source": [
    "üìå Works best on 1‚Äì3 paragraphs.\n",
    "üì∏ *Screenshot placeholder: summary output from above block*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b23d28c",
   "metadata": {},
   "source": [
    "### üåç Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc1b20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = pipeline(\"translation_en_to_fr\")\n",
    "translator(\"Climate change is the biggest challenge of our generation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55ca064",
   "metadata": {},
   "source": [
    "‚úÖ Available language pairs include:\n",
    "- `translation_en_to_de`\n",
    "- `translation_fr_to_en`\n",
    "- `translation_en_to_zh`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbb2589",
   "metadata": {},
   "source": [
    "### üîé Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25790a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(\"Maria works at OpenAI in San Francisco.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704f6ee9",
   "metadata": {},
   "source": [
    "You‚Äôll get results like:\n",
    "```python\n",
    "[{'entity_group': 'PER', 'word': 'Maria'}, {'entity_group': 'ORG', 'word': 'OpenAI'}]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56afeda1",
   "metadata": {},
   "source": [
    "## üß† Summary\n",
    "- Hugging Face pipelines let you run powerful LLM tasks in 2 lines of code\n",
    "- You‚Äôve run single and batch sentiment classification\n",
    "- You‚Äôve seen summarization, translation, and entity recognition\n",
    "- These are real production-grade tools for research, journalism, education, and policy analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebe3331",
   "metadata": {},
   "source": [
    "üëâ This is your **launch point** for advanced workflows ‚Äî where you combine inputs, apply models, and output structured insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96af835f",
   "metadata": {},
   "source": [
    "üîó What‚Äôs Next?\n",
    "Next, we‚Äôll go deeper:\n",
    "\n",
    "Compare outputs from different providers (Gemini, OpenAI, Hugging Face)\n",
    "\n",
    "Examine tokenization, input formatting, and response parsing\n",
    "\n",
    "Understand the underlying input/output logic of LLMs\n",
    "\n",
    "Begin modularizing your pipeline for structured tasks and automation\n",
    "\n",
    "üìò Jump to: [huggingface_pipeline_bonus.ipynb](huggingface_pipeline_bonus.ipynb)\n",
    "\n",
    "\"You just spoke to a model. Next, we‚Äôll teach you how to make it listen precisely.\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
