{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "222ef2e663d74fef8aac5a00deeb5b79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f504f68f9764238ad69ed7163530f9a",
              "IPY_MODEL_27654c9eb46c44ee8192285b5d46d17f",
              "IPY_MODEL_4e191c55936740e7b59710917fcef113"
            ],
            "layout": "IPY_MODEL_15538d167cd74435b0bf9525906286ca"
          }
        },
        "5f504f68f9764238ad69ed7163530f9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dfd0940a42a4b33a3fcbb39f7772e8a",
            "placeholder": "​",
            "style": "IPY_MODEL_cdc5206db24c4775ac35eb01fac2b1b6",
            "value": "Map: 100%"
          }
        },
        "27654c9eb46c44ee8192285b5d46d17f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9ca54a6a2504a33859495fdd1866ca8",
            "max": 6,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_934a437170c043da942922d1ad28595d",
            "value": 6
          }
        },
        "4e191c55936740e7b59710917fcef113": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7cb6fb6e6c947209400376fce69d381",
            "placeholder": "​",
            "style": "IPY_MODEL_040019fb41d349d1b1a6d752ba7e08ed",
            "value": " 6/6 [00:00&lt;00:00, 119.01 examples/s]"
          }
        },
        "15538d167cd74435b0bf9525906286ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dfd0940a42a4b33a3fcbb39f7772e8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdc5206db24c4775ac35eb01fac2b1b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9ca54a6a2504a33859495fdd1866ca8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "934a437170c043da942922d1ad28595d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7cb6fb6e6c947209400376fce69d381": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "040019fb41d349d1b1a6d752ba7e08ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f392b205697241e7a2514d678c59f9d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86f5f4d6d1e5438d81d6cfad10f304bd",
              "IPY_MODEL_6cc04473e790478a89784c6132c91776",
              "IPY_MODEL_ce8527151d214d6b97123f6fda3b266a"
            ],
            "layout": "IPY_MODEL_bd4db52b0e8445309d49e3237159d8cd"
          }
        },
        "86f5f4d6d1e5438d81d6cfad10f304bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d99487e14e6f479a907dd8e724ef022e",
            "placeholder": "​",
            "style": "IPY_MODEL_d4d0bd04c3d14cb99eb00b2abab27e28",
            "value": "Map: 100%"
          }
        },
        "6cc04473e790478a89784c6132c91776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ae0d2b3dc54415ab3b926576bd7487c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8bdfa0849ffa49d68ca2337a9264c223",
            "value": 2
          }
        },
        "ce8527151d214d6b97123f6fda3b266a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8710ea65dd74f6d83a81bc17b358546",
            "placeholder": "​",
            "style": "IPY_MODEL_226f94028991480995478d0fefda7f02",
            "value": " 2/2 [00:00&lt;00:00, 95.54 examples/s]"
          }
        },
        "bd4db52b0e8445309d49e3237159d8cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d99487e14e6f479a907dd8e724ef022e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4d0bd04c3d14cb99eb00b2abab27e28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ae0d2b3dc54415ab3b926576bd7487c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bdfa0849ffa49d68ca2337a9264c223": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e8710ea65dd74f6d83a81bc17b358546": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "226f94028991480995478d0fefda7f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Getting better results with fine-tuning"
      ],
      "metadata": {
        "id": "GxmV0KHjAzpk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is fine-tuning\n",
        "\n",
        "**Fine-tuning** is a transfer learning technique where a pre-trained model (like BERT, GPT, or ResNet) is further trained on a new, task-specific dataset to adapt it to a particular application. It leverages the general knowledge the model has already learned while specializing it for a specific use case.\n",
        "\n"
      ],
      "metadata": {
        "id": "sdZdmYHJFJbN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why Fine-Tuning?\n",
        "\n",
        "**Key Benefits:**\n",
        "\n",
        "- Requires Less Data:\n",
        "\n",
        "Pre-trained models already understand general patterns (e.g., language structure for NLP, visual features for CV).\n",
        "\n",
        "Fine-tuning adapts them to a new task with far fewer examples than training from scratch.\n",
        "\n",
        "- Faster Training:\n",
        "\n",
        "The model starts with learned weights, so it converges faster than training from random initialization.\n",
        "\n",
        "- Better Performance:\n",
        "\n",
        "Fine-tuned models often outperform models trained only on the target dataset.\n",
        "\n",
        "## How Fine-Tuning Works\n",
        "\n",
        "**Step-by-Step Process:**\n",
        "\n",
        "- Start with a Pre-trained Model\n",
        "\n",
        "Example: bert-base-uncased (a general-purpose language model).\n",
        "\n",
        "- Modify the Model Head\n",
        "\n",
        "Replace the final layer (e.g., for classification, regression, or a new task).\n",
        "\n",
        "- Train on New Data\n",
        "\n",
        "Keep most of the model frozen (weights fixed).\n",
        "\n",
        "Only update the last few layers (or use LoRA for parameter-efficient tuning).\n",
        "\n",
        "- Evaluate & Deploy\n",
        "\n",
        "Test on a held-out dataset.\n",
        "\n",
        "Save the fine-tuned model for inference."
      ],
      "metadata": {
        "id": "4txajrtFFTKh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Core Trainer Setup\n",
        "\n",
        "#### Basic Instantiation\n",
        "\n",
        "**model**: The PyTorch model to train (must be nn.Module)\n",
        "\n",
        "**args**: Configured TrainingArguments object\n",
        "\n",
        "**train_dataset**: Preprocessed training data (Dataset object)\n",
        "\n",
        "**eval_dataset**: Optional validation data"
      ],
      "metadata": {
        "id": "jDbVqiHP_L2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not run = example only\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    evaluation_strategy=\"epoch\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")"
      ],
      "metadata": {
        "id": "woRXxkE3_Z-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Essential Training Arguments\n",
        "\n",
        "Pro Tip: Use fp16=True for automatic mixed-precision training on GPUs.\n",
        "\n"
      ],
      "metadata": {
        "id": "A2yYLrhP_jji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not run = example only\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./saved_models\",  # Save directory\n",
        "    num_train_epochs=3,          # Total epochs\n",
        "    per_device_train_batch_size=16,  # Batch size\n",
        "    learning_rate=2e-5,          # Initial LR\n",
        "    evaluation_strategy=\"steps\",  # When to evaluate\n",
        "    eval_steps=500,              # Evaluate every N steps\n",
        "    save_strategy=\"epoch\",       # When to save\n",
        "    load_best_model_at_end=True, # Keep best checkpoint\n",
        "    metric_for_best_model=\"accuracy\"\n",
        ")"
      ],
      "metadata": {
        "id": "l10Eufxc_K66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding Custom Metrics\n",
        "\n",
        "**Supported Metrics:**\n",
        "\n",
        "**Classification**: Accuracy, F1, Precision/Recall\n",
        "\n",
        "**Regression**: MSE, MAE\n",
        "\n",
        "**Custom**: Any function accepting (eval_pred, labels)"
      ],
      "metadata": {
        "id": "F5SojO--_KkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not run = example only\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(labels, predictions),\n",
        "        \"custom_metric\": custom_function(logits, labels)\n",
        "    }\n",
        "\n",
        "trainer = Trainer(\n",
        "    ...,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "F-pKsvL__Jw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks & Extensions"
      ],
      "metadata": {
        "id": "NhD98VF-ABpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Do not run = example only\n",
        "\n",
        "from transformers import (\n",
        "    EarlyStoppingCallback,\n",
        "    TensorBoardCallback\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    ...,\n",
        "    callbacks=[\n",
        "        EarlyStoppingCallback(early_stopping_patience=2),\n",
        "        TensorBoardCallback(log_dir=\"./logs\")\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "7Z6P8wfoAFQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Execution"
      ],
      "metadata": {
        "id": "yOmHZlAyALkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()  # Runs full training loop\n"
      ],
      "metadata": {
        "id": "E3oVSkKIAPeW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation & Prediction"
      ],
      "metadata": {
        "id": "rvvRVXrVAT6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_results = trainer.evaluate()\n",
        "print(eval_results)\n",
        "\n",
        "predictions = trainer.predict(test_dataset)\n",
        "print(predictions.metrics)  # Test set metrics\n",
        "print(predictions.predictions)  # Raw safe"
      ],
      "metadata": {
        "id": "NK0AHZVEAWZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Key Packages:**\n",
        "\n",
        "**transformers**: Provides pretrained models (BERT, DistilBERT, etc.) and training utilities\n",
        "\n",
        "**datasets**: Handles dataset loading and preprocessing\n",
        "\n",
        "**peft**: Enables Parameter-Efficient Fine-Tuning (LoRA)\n",
        "\n",
        "**accelerate**: Optimizes training for GPUs/TPUs\n",
        "\n",
        "**evaluate**: Standardized metric computation\n",
        "\n",
        "**Why These Versions?**\n",
        "\n",
        "transformers>=4.40.0: Ensures compatibility with LoRA implementations\n",
        "\n",
        "peft>=0.10.0: Contains stable LoRA implementations"
      ],
      "metadata": {
        "id": "q16Pjr0txKFt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU Verification\n",
        "\n",
        "**torch.cuda.is_available():** Checks for NVIDIA GPU\n",
        "\n",
        "**device variable:** Sets tensors to GPU (CUDA) or CPU\n",
        "\n",
        "**Why Important?**\n",
        "\n",
        "GPUs provide ~50x speedup for deep learning\n",
        "\n",
        "Automatic fallback to CPU ensures code runs without GPU"
      ],
      "metadata": {
        "id": "_psz6WL5xWfq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Cell 1] - Package Installation\n",
        "# -------------------------------\n",
        "# Install necessary libraries with specific versions\n",
        "# transformers: Main library for pretrained models\n",
        "# datasets: For dataset handling\n",
        "# peft: Parameter-Efficient Fine-Tuning\n",
        "# accelerate: For distributed training\n",
        "# evaluate: For metrics calculation\n",
        "!pip install -q transformers>=4.40.0 datasets peft>=0.10.0 accelerate evaluate"
      ],
      "metadata": {
        "id": "waKN9YBeq4zW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creates a labeled dataset for stance classification.\n",
        "\n",
        "**Structure**:\n",
        "\n",
        "**text**: Example sentences\n",
        "\n",
        "**label**: 0 (Support), 1 (Neutral), 2 (Oppose)\n",
        "\n",
        "**Key Operations:**\n",
        "\n",
        ".train_test_split(test_size=0.25): 75/25 train-test split\n",
        "\n",
        "seed=42: Ensures reproducible splits\n",
        "\n",
        "**Dataset Size**:\n",
        "\n",
        "6 training examples\n",
        "\n",
        "2 test examples (minimum for demonstration)\n",
        "\n"
      ],
      "metadata": {
        "id": "4v86SH0dxqVf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Cell 2] - GPU Verification\n",
        "# ---------------------------\n",
        "# Check for GPU availability and set device\n",
        "# CUDA enables ~50x faster training on NVIDIA GPUs\n",
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "if device == 'cpu':\n",
        "    print(\"Warning: Training will be very slow without GPU!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IbtaV4BvpPw",
        "outputId": "6e2fe71b-01b5-4c49-c177-f435aac3686d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Preparation\n",
        "\n",
        "Initializes a pretrained model with LoRA adaptation.\n",
        "\n",
        "**Key Components:**\n",
        "\n",
        "Base Model: distilbert-base-uncased\n",
        "\n",
        "Lightweight version of BERT\n",
        "\n",
        "~66M parameters (vs BERT's 110M)\n",
        "\n",
        "**LoRA Configuration:**\n",
        "\n",
        "r=8: Rank of low-rank matrices (smaller = more efficient)\n",
        "\n",
        "lora_alpha=16: Scaling factor for LoRA weights\n",
        "\n",
        "target_modules: Applies LoRA to query/value layers (most impactful)\n",
        "\n",
        "**Classification Head: **\n",
        "\n",
        "num_labels=3: Matches our 3-class task"
      ],
      "metadata": {
        "id": "9wB3Mpibx1MT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Cell 3] - Dataset Preparation\n",
        "# -----------------------------\n",
        "# Create a small labeled dataset for stance classification\n",
        "# 0=Support, 1=Neutral, 2=Oppose\n",
        "# Using 25% test split gives 6 train, 2 test examples\n",
        "from datasets import Dataset\n",
        "\n",
        "examples = {\n",
        "    \"text\": [\n",
        "        \"The policy is needed to combat climate change.\",  # Support\n",
        "        \"This environmental initiative is crucial\",        # Support\n",
        "        \"I'm undecided about this policy\",                # Neutral\n",
        "        \"Need more information to decide\",                # Neutral\n",
        "        \"This infringes on personal rights\",              # Oppose\n",
        "        \"Government overreach must be stopped\",           # Oppose\n",
        "        \"This legislation will save lives\",               # Support\n",
        "        \"The proposal has some merits but needs work\"     # Neutral\n",
        "    ],\n",
        "    \"label\": [0, 0, 1, 1, 2, 2, 0, 1]\n",
        "}\n",
        "\n",
        "dataset = Dataset.from_dict(examples).train_test_split(\n",
        "    test_size=0.25,  # 25% for testing\n",
        "    seed=42          # Fixed random seed for reproducibility\n",
        ")\n",
        "print(f\"Train samples: {len(dataset['train'])}\")\n",
        "print(f\"Test samples: {len(dataset['test'])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_no-cb9Gvq8M",
        "outputId": "e8689fb1-63be-4b43-d805-b7ca2d3ba395"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples: 6\n",
            "Test samples: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uE6IEM6vyFlG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n",
        "\n",
        "**Key Components:**\n",
        "\n",
        "**Base Model:** distilbert-base-uncased\n",
        "\n",
        "Lightweight version of BERT\n",
        "\n",
        "~66M parameters (vs BERT's 110M)\n",
        "\n",
        "\n",
        "**LoRA Configuration:**\n",
        "\n",
        "r=8: Rank of low-rank matrices (smaller = more efficient)\n",
        "\n",
        "lora_alpha=16: Scaling factor for LoRA weights\n",
        "\n",
        "target_modules: Applies LoRA to query/value layers (most impactful)\n",
        "\n",
        "\n",
        "**Classification Head:**\n",
        "\n",
        "num_labels=3: Matches our 3-class task\n",
        "\n"
      ],
      "metadata": {
        "id": "1zb7wzMnymbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Cell 4] - Model Initialization\n",
        "# -------------------------------\n",
        "# Using DistilBERT for efficiency with LoRA adaptation\n",
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "model_name = \"distilbert-base-uncased\"  # Lightweight BERT variant\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Initialize with 3 output classes (Support/Neutral/Oppose)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=3  # Must match our label space\n",
        ").to(device)\n",
        "\n",
        "# LoRA Configuration:\n",
        "# r=8: Rank of low-rank adaptation matrices\n",
        "# lora_alpha=16: Scaling factor for LoRA weights\n",
        "# target_modules: Apply to query and value layers\n",
        "peft_config = LoraConfig(\n",
        "    task_type=\"SEQ_CLS\",  # Sequence Classification\n",
        "    r=8,                 # LoRA rank\n",
        "    lora_alpha=16,       # LoRA alpha\n",
        "    lora_dropout=0.1,    # Dropout for LoRA layers\n",
        "    target_modules=[\"q_lin\", \"v_lin\"]  # Apply to query/value weights\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, peft_config)\n",
        "model.print_trainable_parameters()  # Show % of trainable params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDWUwOcWvuC3",
        "outputId": "9f2c5814-711f-4a6c-854b-9c403c1fc11a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 740,355 || all params: 67,696,134 || trainable%: 1.0936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tokenization\n",
        "\n",
        "Converts text to numeric tokens the model understands.\n",
        "\n",
        "T**okenization Process:**\n",
        "\n",
        "**Padding**: Fills shorter sequences with zeros to match max_length\n",
        "\n",
        "**Truncation**: Cuts sequences longer than 512 tokens\n",
        "\n",
        "**Special Tokens**: Adds [CLS], [SEP] automatically\n",
        "\n",
        "\n",
        "**Why Important?:**\n",
        "\n",
        "Transformers require fixed-length numeric input\n",
        "\n",
        "Batched processing improves speed"
      ],
      "metadata": {
        "id": "eEct8NSAygxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Cell 5] - Tokenization\n",
        "# -----------------------\n",
        "# Convert text to model-compatible token IDs\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        padding=\"max_length\",  # Pad to max length\n",
        "        truncation=True,       # Truncate long sequences\n",
        "        max_length=512         # BERT's max input size\n",
        "    )\n",
        "\n",
        "# Apply to both train and test sets\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "222ef2e663d74fef8aac5a00deeb5b79",
            "5f504f68f9764238ad69ed7163530f9a",
            "27654c9eb46c44ee8192285b5d46d17f",
            "4e191c55936740e7b59710917fcef113",
            "15538d167cd74435b0bf9525906286ca",
            "3dfd0940a42a4b33a3fcbb39f7772e8a",
            "cdc5206db24c4775ac35eb01fac2b1b6",
            "c9ca54a6a2504a33859495fdd1866ca8",
            "934a437170c043da942922d1ad28595d",
            "a7cb6fb6e6c947209400376fce69d381",
            "040019fb41d349d1b1a6d752ba7e08ed",
            "f392b205697241e7a2514d678c59f9d5",
            "86f5f4d6d1e5438d81d6cfad10f304bd",
            "6cc04473e790478a89784c6132c91776",
            "ce8527151d214d6b97123f6fda3b266a",
            "bd4db52b0e8445309d49e3237159d8cd",
            "d99487e14e6f479a907dd8e724ef022e",
            "d4d0bd04c3d14cb99eb00b2abab27e28",
            "0ae0d2b3dc54415ab3b926576bd7487c",
            "8bdfa0849ffa49d68ca2337a9264c223",
            "e8710ea65dd74f6d83a81bc17b358546",
            "226f94028991480995478d0fefda7f02"
          ]
        },
        "id": "ZxJN_7L_vwch",
        "outputId": "d294b641-301e-4989-a250-594ff546f3fb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "222ef2e663d74fef8aac5a00deeb5b79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f392b205697241e7a2514d678c59f9d5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Configuration\n",
        "\n",
        "**Key Parameters Explained:**\n",
        "\n",
        "Batch size 8 fits comfortably in 16GB GPU memory\n",
        "\n",
        "Step-based eval/save is more flexible than epoch-based\n",
        "\n",
        "2e-4 LR prevents catastrophic forgetting of pretrained knowledge\n",
        "\n",
        "Disabled W&B reporting (report_to=\"none\") for simplicity\n",
        "\n"
      ],
      "metadata": {
        "id": "yyTVi5d5zUl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Cell 6] - Training Configuration\n",
        "# ---------------------------------\n",
        "# Critical hyperparameters for the training process\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./output\",          # Save directory\n",
        "    per_device_train_batch_size=8,  # Batch size per GPU\n",
        "    per_device_eval_batch_size=8,   # Eval batch size\n",
        "    eval_strategy=\"steps\",          # Evaluate every N steps\n",
        "    eval_steps=20,                  # Evaluate every 20 steps\n",
        "    save_strategy=\"steps\",          # Save checkpoints by steps\n",
        "    save_steps=40,                  # Save every 40 steps\n",
        "    logging_steps=10,               # Log every 10 steps\n",
        "    learning_rate=2e-4,             # Optimal for fine-tuning\n",
        "    num_train_epochs=3,             # Total training epochs\n",
        "    load_best_model_at_end=True,    # Keep best checkpoint\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    report_to=\"none\",               # Disable external logging\n",
        "    remove_unused_columns=False     # Required for some versions\n",
        ")"
      ],
      "metadata": {
        "id": "knLpXo3uvyXL"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics Setup\n",
        "\n",
        "- **Raw Logits (Model Output)**\n",
        "\n",
        "After input text passes through the model, it outputs logits: raw, unnormalized prediction scores for each class (e.g., Support, Neutral, Oppose).\n",
        "\n",
        "Example: [2.3, 1.1, -0.4] → higher values suggest higher model confidence.\n",
        "\n",
        "- **Argmax (Pick the Top Score)**\n",
        "\n",
        "We use argmax to find the index of the highest score → this becomes the predicted label.\n",
        "\n",
        "In our example: argmax([2.3, 1.1, -0.4]) = 0 → label 0 = Support\n",
        "\n",
        "- **Compare to Ground Truth**\n",
        "\n",
        "We compare each predicted label to the true label from the dataset.\n",
        "\n",
        "If predicted label == true label → it’s counted as a correct prediction.\n",
        "\n",
        "**Calculate Accuracy**\n",
        "\n",
        "Accuracy is computed as:\n",
        "\n",
        "Accuracy = Number of Correct Predictions/ Total Number of Predictions​\n",
        "\n",
        "This gives a simple metric of model performance: \"What fraction of the predictions were correct?\""
      ],
      "metadata": {
        "id": "2hwF0xKhzkvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Cell 7] - Metrics Setup\n",
        "# ------------------------\n",
        "# Configure evaluation metrics\n",
        "import numpy as np\n",
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)  # Convert logits to predictions\n",
        "    return metric.compute(\n",
        "        predictions=predictions,\n",
        "        references=labels\n",
        "    )"
      ],
      "metadata": {
        "id": "1122AvPYv1K0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trainer setup\n",
        "\n",
        "[Trainer]\n",
        "\n",
        "├── Model\n",
        "\n",
        "├── Training Args\n",
        "\n",
        "├── Train Data\n",
        "\n",
        "├── Eval Data\n",
        "\n",
        "├── Metrics\n",
        "\n",
        "└── Callbacks\n",
        "\n",
        "Trainer class handles the entire training loop\n",
        "\n",
        "Early stopping prevents overfitting (patience=2 evaluations)\n",
        "\n",
        "Callbacks can add TensorBoard, checkpointing, etc.\n",
        "\n",
        "All components from previous cells come together here"
      ],
      "metadata": {
        "id": "jpO7Blxc0nYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Cell 8] - Trainer Initialization\n",
        "# --------------------------------\n",
        "# Setup the complete training pipeline\n",
        "from transformers import Trainer, EarlyStoppingCallback\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[\n",
        "        EarlyStoppingCallback(\n",
        "            early_stopping_patience=2  # Stop if no improvement for 2 evals\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBF-N6civ3Tr",
        "outputId": "46180cb3-3fdb-45b3-da16-38b686ca4606"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Execution\n",
        "\n",
        "- Automatically handles:\n",
        "\n",
        "- Gradient accumulation\n",
        "\n",
        "- Mixed precision training\n",
        "\n",
        "- Checkpoint saving\n",
        "\n",
        "- Progress bars show real-time metrics\n",
        "\n",
        "- Training loss should decrease monotonically\n",
        "\n",
        "- Validation metrics may fluctuate"
      ],
      "metadata": {
        "id": "g3dkCtj70ySR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Cell 9] - Model Training\n",
        "# -------------------------\n",
        "# Execute the training process\n",
        "trainer.train()  # This runs the full training loop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "oss53DKDv5Yg",
        "outputId": "804d6ada-14b5-4bef-888e-3e0621cbd0ee"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:01, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3, training_loss=1.059674898783366, metrics={'train_runtime': 1.3207, 'train_samples_per_second': 13.63, 'train_steps_per_second': 2.272, 'total_flos': 2425394368512.0, 'train_loss': 1.059674898783366, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction Function\n",
        "\n"
      ],
      "metadata": {
        "id": "gXSDhIKS1Yc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Cell 10] - Prediction Function\n",
        "# ------------------------------\n",
        "# Create a reusable prediction function\n",
        "def predict(text):\n",
        "    # 1. Tokenization\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"pt\",           # Return PyTorch tensors\n",
        "        truncation=True,               # Cut excess tokens\n",
        "        max_length=512                 # BERT's max capacity\n",
        "    ).to(device)                       # GPU/CPU placement\n",
        "\n",
        "    # 2. Inference Mode\n",
        "    with torch.no_grad():              # Disable gradient tracking\n",
        "        outputs = model(**inputs)      # Forward pass\n",
        "\n",
        "    # 3. Probability Conversion\n",
        "    probs = torch.nn.functional.softmax(\n",
        "        outputs.logits,                # Raw model outputs\n",
        "        dim=-1                         # Normalize across classes\n",
        "    )\n",
        "\n",
        "    # 4. Result Formatting\n",
        "    return {\n",
        "        \"text\": text,\n",
        "        \"prediction\": [\"Support\", \"Neutral\", \"Oppose\"][torch.argmax(probs).item()],\n",
        "        \"confidence\": torch.max(probs).item()  # Highest class probability\n",
        "    }\n",
        "\n",
        "# Test prediction\n",
        "print(predict(\"This policy is fundamentally flawed\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5W9RKHhWv7Ml",
        "outputId": "214e9058-d7d7-4792-84f4-d1bc1f78c7d9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'This policy is fundamentally flawed', 'prediction': 'Support', 'confidence': 0.42485958337783813}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Saving & Loading\n",
        "\n",
        "safe_serialization=True: Prevents pickle vulnerabilities (Uses safetensors format)\n",
        "\n",
        "PeftConfig:\tPreserves adapter architecture, contains LoRA rank/target modules\n",
        "\n",
        "num_labels=3:\tMust match training setup, critical for correct head initialization\n",
        "\n",
        "**Best Practice: **Always save both model AND tokenizer to ensure compatible inference later.\n",
        "\n",
        "When **safe_serialization=True** is set in save_pretrained(), the model weights are saved in the safetensors format instead of Python's native pickle format. This addresses critical security vulnerabilities inherent to pickle."
      ],
      "metadata": {
        "id": "LicxXBqe8eIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Cell 11] - Model Saving/Loading\n",
        "# -------------------------------\n",
        "# Save the fine-tuned model for later use\n",
        "model.save_pretrained(\"./policy-stance-lora\", safe_serialization=True)\n",
        "tokenizer.save_pretrained(\"./policy-stance-lora\")\n",
        "\n",
        "# Proper loading procedure\n",
        "from peft import PeftModel, PeftConfig\n",
        "\n",
        "# 1. Load config to get base model info\n",
        "config = PeftConfig.from_pretrained(\"./policy-stance-lora\")\n",
        "\n",
        "# 2. Initialize base model with correct class count\n",
        "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    config.base_model_name_or_path,\n",
        "    num_labels=3  # Must match training setup\n",
        ")\n",
        "\n",
        "# 3. Load the PEFT adapter weights\n",
        "loaded_model = PeftModel.from_pretrained(base_model, \"./policy-stance-lora\")\n",
        "loaded_model = loaded_model.to(device)  # Move to GPU if available"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-EqKEQsv9DA",
        "outputId": "74beae39-1bde-4a4c-9cef-4ddee634f770"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation Setup\n",
        "\n",
        "**Class-wise Metrics**:  Precision/Recall/F1\n",
        "\n",
        "**Confidence Tracking**: Average prediction certainty\n",
        "\n",
        "**Label Alignment**: Exact match accuracy\n",
        "\n",
        "**Note**: Uses scikit-learn's report for comprehensive metrics beyond basic accuracy.\n",
        "\n"
      ],
      "metadata": {
        "id": "smZl76Yu9B47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# [Cell 12] - Evaluation Setup\n",
        "# ---------------------------\n",
        "# Install additional evaluation tools\n",
        "!pip install -q scikit-learn\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_model(model, tokenizer, dataset):\n",
        "    label_names = [\"Support\", \"Neutral\", \"Oppose\"]\n",
        "    true_labels = dataset[\"label\"]\n",
        "    preds = []\n",
        "    confs = []\n",
        "\n",
        "    for text in dataset[\"text\"]:\n",
        "        result = predict(model, tokenizer, text)\n",
        "        preds.append(label_names.index(result[\"prediction\"]))\n",
        "        confs.append(result[\"confidence\"])\n",
        "\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(true_labels, preds, target_names=label_names))\n",
        "    print(f\"Average Confidence: {np.mean(confs):.1%}\")\n",
        "    return preds"
      ],
      "metadata": {
        "id": "DPvwZl0nv_xb"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 13: Prediction Function\n",
        "def predict(model, tokenizer, text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "    return {\n",
        "        \"text\": text,\n",
        "        \"prediction\": [\"Support\", \"Neutral\", \"Oppose\"][torch.argmax(probs).item()],\n",
        "        \"confidence\": torch.max(probs).item()\n",
        "    }"
      ],
      "metadata": {
        "id": "bWzam5J-wlsP"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "JemX0EOw94cA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation**: Random initialization typically shows:\n",
        "\n",
        "~33% accuracy for 3-class problems\n",
        "\n",
        "High recall on frequent classes\n",
        "\n",
        "Zero precision where no predictions hit the class\n",
        "\n"
      ],
      "metadata": {
        "id": "ueQi6-YG9tmx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-Training Evaluation\n",
        "Baseline Assessment"
      ],
      "metadata": {
        "id": "bczOlJoI-U68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 14: Run Evaluations\n",
        "print(\"=== Before Training ===\")\n",
        "baseline_preds = evaluate_model(model, tokenizer, dataset[\"test\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmqIEwrUwrxV",
        "outputId": "3dfe6b63-f284-495e-b45d-74bc87f54e0c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Before Training ===\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Support       0.00      0.00      0.00       0.0\n",
            "     Neutral       0.00      0.00      0.00       1.0\n",
            "      Oppose       0.00      0.00      0.00       1.0\n",
            "\n",
            "    accuracy                           0.00       2.0\n",
            "   macro avg       0.00      0.00      0.00       2.0\n",
            "weighted avg       0.00      0.00      0.00       2.0\n",
            "\n",
            "Average Confidence: 38.7%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Execution\n",
        "\n",
        "**Behind the Scenes:**\n",
        "\n",
        "**Forward Pass**: Computes logits\n",
        "\n",
        "**Loss Calculation**: Cross-entropy between logits/labels\n",
        "\n",
        "**Backward Pass**: Gradient computation through LoRA layers only\n",
        "\n",
        "**Weight Update**: AdamW optimizer step\n",
        "\n",
        "**Key Monitoring Metrics:**\n",
        "\n",
        "**Training Loss**: Should decrease monotonically\n",
        "\n",
        "**Eval Accuracy**: Should increase with oscillations\n",
        "\n",
        "**GPU Utilization:**  Should be >80% for efficient training\n",
        "\n"
      ],
      "metadata": {
        "id": "_mkBIrDw-fe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== Training ===\")\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "wP0_Vbjzwyve",
        "outputId": "cd58f62d-3f34-400b-a3fa-ec9e23f3e1ac"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Training ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3/3 00:01, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3, training_loss=0.9966476758321127, metrics={'train_runtime': 1.4745, 'train_samples_per_second': 12.208, 'train_steps_per_second': 2.035, 'total_flos': 2425394368512.0, 'train_loss': 0.9966476758321127, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Post-Training Evaluation\n",
        "\n",
        "**Analysis Framework:**\n",
        "\n",
        "**Quantitative Improvement:**\n",
        "\n",
        "Absolute accuracy delta (e.g., +45%)\n",
        "\n",
        "Confidence increase (e.g., 33% → 85%)\n",
        "\n",
        "**Qualitative Checks:**\n",
        "\n",
        "Misclassification patterns\n",
        "\n",
        "Class-wise performance gaps\n",
        "\n"
      ],
      "metadata": {
        "id": "3hNe73kv-0IR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n=== After Training ===\")\n",
        "trained_preds = evaluate_model(model, tokenizer, dataset[\"test\"])\n",
        "\n",
        "# Cell 5: Improvement Analysis\n",
        "improvement = (np.array(trained_preds) == np.array(dataset[\"test\"][\"label\"])).mean() - \\\n",
        "              (np.array(baseline_preds) == np.array(dataset[\"test\"][\"label\"])).mean()\n",
        "print(f\"\\nAbsolute Accuracy Improvement: {improvement:.1%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSkYz7vYw3Ku",
        "outputId": "7472770e-ddd6-4721-b92f-8b1c73028ab3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== After Training ===\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Support       0.00      0.00      0.00       0.0\n",
            "     Neutral       0.00      0.00      0.00       1.0\n",
            "      Oppose       0.00      0.00      0.00       1.0\n",
            "\n",
            "    accuracy                           0.00       2.0\n",
            "   macro avg       0.00      0.00      0.00       2.0\n",
            "weighted avg       0.00      0.00      0.00       2.0\n",
            "\n",
            "Average Confidence: 43.2%\n",
            "\n",
            "Absolute Accuracy Improvement: 0.0%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RsIkmomewUT8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}