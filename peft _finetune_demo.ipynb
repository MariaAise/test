{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77b180a7",
   "metadata": {},
   "source": [
    "# Before You Start\n",
    "Ensure you are running on a GPU-enabled environment for faster training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e69ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"Warning: Using CPU - training will be slow\")\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc112135",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "examples = {\n",
    "    \"text\": [\n",
    "        \"The policy is needed to combat climate change.\", \n",
    "        \"This environmental initiative is crucial\",\n",
    "        \"I'm undecided about this policy\",\n",
    "        \"Need more information to decide\",\n",
    "        \"This infringes on personal rights\",\n",
    "        \"Government overreach must be stopped\"\n",
    "    ],\n",
    "    \"label\": [0, 0, 1, 1, 2, 2]\n",
    "}\n",
    "\n",
    "dataset = Dataset.from_dict(examples).train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc45e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    per_device_train_batch_size=16,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0ce452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839ab36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    return {\n",
    "        \"prediction\": [\"Supportive\", \"Neutral\", \"Opposed\"][torch.argmax(probs)],\n",
    "        \"confidence\": torch.max(probs).item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5740a76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./policy-stance-lora\")\n",
    "from peft import PeftModel\n",
    "loaded_model = PeftModel.from_pretrained(model, \"./policy-stance-lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be00ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
